{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape data\n",
    "\n",
    "def get_epl_table(url):\n",
    "    # query the website and return the html to the variable 'page'\n",
    "    page = urllib.request.urlopen(urlpage)\n",
    "    # parse the html using beautiful soup and store in variable 'soup'\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    #print(soup.pettrify())\n",
    "    \n",
    "    # find results within table\n",
    "    table = soup.find('table', attrs={'class': 'standing-table__table'})\n",
    "    results = table.find_all('tr')\n",
    "    # print the number of rows in the table\n",
    "    #print('Number of results', len(results))\n",
    "    \n",
    "    # create and write headers to a list \n",
    "    rows = []\n",
    "    rows.append(['Rank', 'Team', 'pl', 'w', 'd', 'l', 'f', 'a', 'gd', 'pts',\n",
    "                'Last 6'])\n",
    "    #print(rows)\n",
    "    \n",
    "    # loop over results\n",
    "    for result in results:\n",
    "        # find all columns per result\n",
    "        data = result.find_all('td')\n",
    "        # check that columns have data \n",
    "        if len(data) == 0: \n",
    "            continue\n",
    "    \n",
    "        # write columns to variables\n",
    "        rank = data[0].getText()\n",
    "        team = data[1].getText()\n",
    "        pl = data[2].getText()\n",
    "        w = data[3].getText()\n",
    "        d = data[4].getText()\n",
    "        l = data[5].getText()\n",
    "        f = data[6].getText()\n",
    "        a = data[7].getText()\n",
    "        gd = data[8].getText()\n",
    "        pts = data[9].getText()\n",
    "        last6 = data[10].getText()\n",
    "    \n",
    "        # remove trailing whitespaces from team\n",
    "        team = team.strip('\\n')\n",
    "    \n",
    "        # write each result to rows\n",
    "        rows.append([rank, team, pl, w, d, l, f, a, gd, pts, last6])\n",
    "\n",
    "    print(rows)\n",
    "    \n",
    "    # at this point you can decide to drop\n",
    "    # the last column before exporting the csv file\n",
    "    # or better still do that later \n",
    "    \n",
    "    # create csv and write rows to output file\n",
    "    with open('premier_league.csv','w', newline='') as f_output:\n",
    "        csv_output = csv.writer(f_output)\n",
    "        csv_output.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Rank', 'Team', 'pl', 'w', 'd', 'l', 'f', 'a', 'gd', 'pts', 'Last 6'], ['1', 'Liverpool', '20', '19', '1', '0', '49', '14', '35', '58', '\\n\\n       \\n'], ['2', 'Leicester City', '21', '14', '3', '4', '46', '19', '27', '45', '\\n\\n       \\n'], ['3', 'Manchester City', '21', '14', '2', '5', '56', '24', '32', '44', '\\n\\n       \\n'], ['4', 'Chelsea', '21', '11', '3', '7', '36', '29', '7', '36', '\\n\\n       \\n'], ['5', 'Manchester United', '21', '8', '7', '6', '32', '25', '7', '31', '\\n\\n       \\n'], ['6', 'Tottenham Hotspur', '21', '8', '6', '7', '36', '30', '6', '30', '\\n\\n       \\n'], ['7', 'Wolverhampton Wanderers', '21', '7', '9', '5', '30', '27', '3', '30', '\\n\\n       \\n'], ['8', 'Sheffield United', '21', '7', '8', '6', '23', '21', '2', '29', '\\n\\n       \\n'], ['9', 'Crystal Palace', '21', '7', '7', '7', '19', '23', '-4', '28', '\\n\\n       \\n'], ['10', 'Arsenal', '21', '6', '9', '6', '28', '30', '-2', '27', '\\n\\n       \\n'], ['11', 'Everton', '21', '7', '4', '10', '24', '32', '-8', '25', '\\n\\n       \\n'], ['12', 'Southampton', '21', '7', '4', '10', '25', '38', '-13', '25', '\\n\\n       \\n'], ['13', 'Newcastle United', '21', '7', '4', '10', '20', '33', '-13', '25', '\\n\\n       \\n'], ['14', 'Brighton and Hove Albion', '21', '6', '6', '9', '25', '29', '-4', '24', '\\n\\n       \\n'], ['15', 'Burnley', '21', '7', '3', '11', '24', '34', '-10', '24', '\\n\\n       \\n'], ['16', 'West Ham United', '20', '6', '4', '10', '25', '32', '-7', '22', '\\n\\n       \\n'], ['17', 'Aston Villa', '21', '6', '3', '12', '27', '37', '-10', '21', '\\n\\n       \\n'], ['18', 'Bournemouth', '21', '5', '5', '11', '20', '32', '-12', '20', '\\n\\n       \\n'], ['19', 'Watford', '21', '4', '7', '10', '17', '34', '-17', '19', '\\n\\n       \\n'], ['20', 'Norwich City', '21', '3', '5', '13', '22', '41', '-19', '14', '\\n\\n       \\n']]\n"
     ]
    }
   ],
   "source": [
    "urlpage = 'https://www.skysports.com/premier-league-table'\n",
    "\n",
    "get_epl_table(urlpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
